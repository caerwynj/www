# Artificial Creativity

From [@dchackethal](https://twitter.com/dchackethal): Artificial creativity requires a function f that given any other function g can implement a copy of g that is a hard to vary implementation.  Function f can call g with any parameters it likes and view the output of g but it can't view the source of g.

Assuming function f is a simulation of a universal explainer, the function contains a comprehending agent to which the explanation is part of its thought process.

In order to simulate the agent the function is a simulation of a larger area of reality that includes the agent and its immediate environment and the thoughts held by the agent. The comprehending agent is composed of abstractions that include senses and thoughts. 

In order to come into existence it will have needed to have accurately represented reality in a way that caused itself to remain in existence and bootstrap to abstractions sophisticated enough to represent things in its environment, itself, thoughts and sensations. With the appropriate mix of abstractions it is able to cause itself to persist in its environment.

A sophisticated function will likely include the existence of itself in the reality it is simulating.  It represents itself as the agent, or a subject that is sensing and doing.

For example, the simulation is running on hardware that interacts with its environment.  That hardware needs maintenance.  The hardware, the environment, and the steps to perform maintenance are all included in the simulation. 

How could this level of sophistication evolve? If the simulation is creating knowledge, possibly without comprehension, it creates a new thing in its environment, which then has to be represented as a new abstraction in the simulation.

Uncomprehending knowledge is created first that changes the environment. This change needs abstractions to represent the newly occurring regularity and to simulate it.  That abstraction then becomes part of new knowledge created in the agent that can be used to change the environment. 

A long chain of such iterations results in abstractions that represent knowing subjects.

A feeling is counterfactual. If the agent sensed X, then Y is how it would have felt to the agent in the simulation function. But since the agent in the simulation now has the knowledge of how it felt then it did feel it. This felt sense is sophisticated knowledge that evolved to have the power to cause itself to persist.  

The simulation can generate the knowledge of how it felt to be the agent. If an agent holds the knowledge of how the sensation felt, it can say that it did feel it.
